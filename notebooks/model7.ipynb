{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ec6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the model: 15\n",
      "Features used in the model during training: ['ieltsMarks', 'toefl_ibt', 'minimumGPA', 'tuitionFeeUSD', 'country_AUS', 'country_CAD', 'country_NZ', 'country_UK', 'country_US', 'courseLevelSimplified_Postgraduate', 'courseLevelSimplified_Undergraduate']\n",
      "Model does not have attribute 'feature_names_in_'. Likely, this model was not fitted with feature names.\n",
      "Warning: Mismatch between the model's expected features and the feature list provided.\n",
      "Adjusted feature list: ['ieltsMarks', 'toefl_ibt', 'minimumGPA', 'tuitionFeeUSD', 'country_AUS', 'country_CAD', 'country_NZ', 'country_UK', 'country_US', 'courseLevelSimplified_Postgraduate', 'courseLevelSimplified_Undergraduate']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m     plt.show()\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Call this function to visualize feature importance\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Now let's also check the feature importance (sort them)\u001b[39;00m\n\u001b[32m     58\u001b[39m sorted_feature_importance = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(gb_model.feature_importances_, feature_cols), reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mplot_feature_importance\u001b[39m\u001b[34m(model, feature_names)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Plot feature importance\u001b[39;00m\n\u001b[32m     47\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m plt.barh(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_idx\u001b[49m\u001b[43m]\u001b[49m, feature_importance[sorted_idx], align=\u001b[33m'\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     49\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mFeature Importance\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 11 is out of bounds for axis 0 with size 11"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Load model and relevant files\n",
    "GB_MODEL_PATH = '../models/gb_model_best.joblib'\n",
    "ML_READY_DATA_PATH = '../data/processed/ml_data6.csv'\n",
    "\n",
    "# Load the processed data\n",
    "df = pd.read_csv(ML_READY_DATA_PATH)\n",
    "\n",
    "# Load the GradientBoosting model\n",
    "gb_model = joblib.load(GB_MODEL_PATH)\n",
    "\n",
    "# Get feature columns for the model (making sure to exclude 'universityRankingNum' and 'uniqueID')\n",
    "feature_cols = ['ieltsMarks', 'toefl_ibt', 'minimumGPA', 'tuitionFeeUSD'] + \\\n",
    "    [col for col in df.columns if col.startswith('country_') or col.startswith('courseLevelSimplified_')]\n",
    "\n",
    "# Check the number of features the model was trained on\n",
    "print(\"Number of features in the model:\", len(gb_model.feature_importances_))\n",
    "print(\"Features used in the model during training:\", feature_cols)\n",
    "\n",
    "# Check the actual feature names the model expects\n",
    "try:\n",
    "    print(\"Model's expected feature names:\", gb_model.feature_names_in_)\n",
    "except AttributeError:\n",
    "    print(\"Model does not have attribute 'feature_names_in_'. Likely, this model was not fitted with feature names.\")\n",
    "\n",
    "# Ensure that the number of features in feature_cols matches the number of model's expected features\n",
    "if len(gb_model.feature_importances_) != len(feature_cols):\n",
    "    print(\"Warning: Mismatch between the model's expected features and the feature list provided.\")\n",
    "    # Trim or adjust the feature list to match the model's actual number of features\n",
    "    feature_cols = feature_cols[:len(gb_model.feature_importances_)]\n",
    "    print(f\"Adjusted feature list: {feature_cols}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    # Get feature importances\n",
    "    feature_importance = model.feature_importances_\n",
    "    \n",
    "    # Sort feature importance\n",
    "    sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], feature_importance[sorted_idx], align='center')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Feature Importance - Gradient Boosting Model\")\n",
    "    plt.show()\n",
    "\n",
    "# Call this function to visualize feature importance\n",
    "plot_feature_importance(gb_model, feature_cols)\n",
    "\n",
    "# Now let's also check the feature importance (sort them)\n",
    "sorted_feature_importance = sorted(zip(gb_model.feature_importances_, feature_cols), reverse=True)\n",
    "print(\"\\nFeature Importance (sorted):\")\n",
    "for importance, feature in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
